import itertools
import os
import re
import numpy as np

from sklearn import preprocessing

from collections import OrderedDict

opcodes = ['add', 'and', 'call', 'cmp', 'dec', 'inc', 'ja', 'jb', 'jbe', 'je', 'jg', 'jmp', 'jnb', 'jne', 'jno', 'jnp', 'jnz', 'jo', 'jp', 'jz', 'lea', 'mov', 'mul', 'nop', 'not', 'or', 'pop', 'push', 'pushf', 'ret', 'retn', 'shld', 'sub', 'test', 'xchg', 'xor']

def count_file(file_name):
    freqs = OrderedDict()
    total = 0

    for opcode in opcodes:
        freqs[opcode] = 0
    freqs['other'] = 0
    file = open(file_name, 'r')
    for line in file.readlines():
        total += 1
        line = re.sub('[^a-z]', '', line.lower())
        if line in opcodes:
            freqs[line] = freqs[line]+1
        else:
            freqs['other'] = freqs['other']+1
    file.close()
    return [num/total for num in freqs.values()]

def get_samples(folder):
    samples = []
    for file_name in os.listdir(folder):
        if file_name.endswith('.txt'):
            samples.append(count_file(folder+file_name))
    return samples


def process_all_files(folders):
    unscaled_samples = []
    targets = []

    for i in range(len(folders)):
        print(folders[i])
        for counted_file in get_samples(folders[i]):
            target = [0]*len(folders) #initialize one hot vector to all zeros
            target[i] = 1       #set target entry to one

            unscaled_samples.append(counted_file)
            targets.append(target)

    return preprocessing.scale(unscaled_samples), targets

root = './samples/original/'
folders = ['winwebsec/', 'zbot/', 'zeroaccess/']
folders = [root+folder for folder in folders]

#inputs, targets= process_all_files(folders)
#np.savez(root+'processed_samples.npz', inputs=inputs, targets=targets)

savedData = np.load(root+'processed_samples.npz')
print(savedData['inputs'].std(axis=0))

